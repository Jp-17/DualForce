# 2026-02-21 | MOVA | 环境搭建与推理测试

## 背景

根据 `/root/autodl-tmp/DualForce/README.md`，为 MOVA（MOSS Video and Audio）项目搭建 conda 环境，下载 checkpoint，并完成最小化推理测试。

MOVA 是一个同步生成视频和音频的开源基础模型，采用非对称双塔架构，通过双向交叉注意力融合视频和音频模态。

---

## 硬件环境

| 项目 | 信息 |
|------|------|
| GPU | NVIDIA GeForce RTX 4090 D |
| 显存 | 24GB |
| CUDA | 12.4 |
| 系统 | Linux 5.15.0-94-generic |
| 磁盘（autodl-tmp） | 350GB 总量，约 278GB 可用 |

---

## 步骤一：创建 conda 环境

### 做了什么
使用系统已有的 miniconda3 创建名为 `mova` 的 conda 环境，Python 版本指定为 3.13（与 pyproject.toml 中 `requires-python = ">=3.12"` 保持一致，同时与 README 示例命令一致）。

```bash
source /root/miniconda3/etc/profile.d/conda.sh
conda create -n mova python=3.13 -y
```

### 为什么这样做
- README 原文使用 `conda create -n mova python=3.13 -y`
- 系统 PATH 中无 `conda` 命令，需要手动 source conda 初始化脚本
- 选择新环境而非在 base 中安装，避免污染系统环境

### 结果
环境创建成功，位于 `/root/miniconda3/envs/mova/`

---

## 步骤二：安装依赖

### 做了什么

**第一步：单独安装 PyTorch（CUDA 12.4 版本）**

```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124
```

原因：pip 默认源（阿里云镜像）没有带 CUDA 的 PyTorch 包，必须从 PyTorch 官方 whl 源安装。若直接 `pip install -e .` 会先从阿里云装 CPU 版 torch，之后再被覆盖，浪费时间。

**第二步：安装 mova 包及其余依赖**

```bash
pip install -e .
```

pyproject.toml 中声明的核心依赖：

```
torch, torchvision, pillow, tqdm, imageio, imageio-ffmpeg,
accelerate, diffusers, transformers<5, mmengine, yunchang,
ftfy, descript-audiotools, einops
```

**第三步：额外安装 bitsandbytes**

```bash
pip install bitsandbytes
```

原因：推理时报错 `ModuleNotFoundError: No module named 'bitsandbytes'`。

分析：`mova/engine/optimizers/__init__.py` 无条件导入了 `bnb_optimizers`，而 `bitsandbytes` 在 pyproject.toml 中仅列为 `[train]` 可选依赖，导致推理也需要安装。这是项目代码的一个设计缺陷（训练专用导入未做条件判断）。

### 结果
所有依赖安装成功，最终安装的关键包版本：

| 包 | 版本 |
|----|------|
| torch | 2.10.0 |
| torchvision | 0.25.0 |
| torchaudio | 2.10.0 |
| diffusers | 0.36.0 |
| transformers | 4.57.6 |
| accelerate | 1.12.0 |
| bitsandbytes | 0.49.2 |

---

## 步骤三：下载 MOVA-360p Checkpoint

### 做了什么

选择 MOVA-360p（而非 MOVA-720p），原因：
- 更小的模型，更快下载，显存需求更低
- 已可支持完整的推理测试（TI2VA）

使用 hf-mirror.com 加速下载（国内网络环境）：

```bash
HF_ENDPOINT=https://hf-mirror.com huggingface-cli download \
    OpenMOSS-Team/MOVA-360p \
    --local-dir /root/autodl-tmp/checkpoints/MOVA-360p
```

### 下载进度监控

通过监控 `.incomplete` 临时文件数量和目录总大小来追踪进度：

| 时刻 | 目录大小 | 未完成文件数 |
|------|---------|------------|
| 开始约 2min | 3.1G | 8 |
| 约 10min | 7.1G | 8 |
| 约 20min | 14G | 8 |
| 约 30min | 28G | 8 |
| 约 45min | 39G | 8 |
| 约 55min | 47G | 7 |
| 约 65min | 50G | 7 |
| 完成 | ~50G | 0 |

总下载耗时约 78 分钟。

### Checkpoint 结构

```
MOVA-360p/
├── model_index.json
├── README.md
├── scheduler/
│   └── scheduler_config.json
├── tokenizer/
├── text_encoder/
│   ├── model-00001-of-00003.safetensors  (~4.6GB)
│   ├── model-00002-of-00003.safetensors  (~4.7GB)
│   └── model-00003-of-00003.safetensors  (~1.4GB)
├── audio_dit/
│   └── diffusion_pytorch_model.safetensors  (~2.7GB)
├── audio_vae/
│   └── diffusion_pytorch_model.safetensors
├── video_dit/
│   ├── diffusion_pytorch_model-00001-of-00003.safetensors
│   ├── diffusion_pytorch_model-00002-of-00003.safetensors
│   └── diffusion_pytorch_model-00003-of-00003.safetensors
├── video_dit_2/
│   ├── diffusion_pytorch_model-00001-of-00003.safetensors
│   ├── diffusion_pytorch_model-00002-of-00003.safetensors
│   └── diffusion_pytorch_model-00003-of-00003.safetensors
├── video_vae/
│   └── diffusion_pytorch_model.safetensors
└── dual_tower_bridge/
    └── diffusion_pytorch_model.safetensors  (~5.0GB)
```

### 结果
下载成功，exit code 0，目录总大小约 50GB（含 .cache 临时文件夹则显示 73GB）。

---

## 步骤四：推理测试

### 做了什么

使用 README 提供的 single person speech 示例命令，关键参数选择：

```bash
export CP_SIZE=1
export CKPT_PATH=/root/autodl-tmp/checkpoints/MOVA-360p/

torchrun \
    --nproc_per_node=$CP_SIZE \
    scripts/inference_single.py \
    --ckpt_path $CKPT_PATH \
    --cp_size $CP_SIZE \
    --height 352 \
    --width 640 \
    --prompt "A man in a blue blazer and glasses speaks in a formal indoor setting, ..." \
    --ref_path "./assets/single_person.jpg" \
    --output_path "./data/samples/single_person.mp4" \
    --seed 42 \
    --offload group
```

### offload 策略选择

README 给出的性能参考（RTX 4090，8秒 360p 视频）：

| 策略 | 显存需求 | Host RAM |
|------|---------|---------|
| `--offload cpu`（组件级） | 48GB | 66.7GB |
| `--offload group`（逐层） | **12GB** | 76.7GB |

RTX 4090 D 仅有 24GB 显存，`--offload cpu` 需要 48GB 会超出，必须使用 `--offload group`。

### 遇到的问题

**问题：** 首次运行报错 `ModuleNotFoundError: No module named 'bitsandbytes'`

**原因：** `mova/engine/optimizers/__init__.py` 无条件导入了训练专用模块，即使是纯推理场景也会触发该导入。

**解决：** 安装 bitsandbytes 后重新运行，推理成功。

### 结果

推理成功，exit code 0，输出文件：

```
./data/samples/single_person.mp4  (4.0MB)
```

---

## 遇到的问题汇总

| 问题 | 原因 | 解决方案 |
|------|------|---------|
| `conda` 命令不在 PATH | shell 初始化未执行 | `source miniconda3/etc/profile.d/conda.sh` |
| pip 安装的 torch 无 CUDA | 阿里云镜像无 CUDA 版 torch | 先从 PyTorch 官方 whl 源单独安装 torch |
| `bitsandbytes` 缺失导致推理失败 | 代码中无条件导入训练专用模块 | `pip install bitsandbytes` |

---

## 最终状态

| 项目 | 状态 |
|------|------|
| conda 环境 `mova` | ✓ 已创建（Python 3.13） |
| 依赖安装 | ✓ 完成（含 bitsandbytes） |
| MOVA-360p checkpoint | ✓ 已下载至 `autodl-tmp/checkpoints/MOVA-360p/` |
| 推理测试 | ✓ 成功，输出 `data/samples/single_person.mp4` |
