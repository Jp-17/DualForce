# DualForce Accelerate FSDP Config (8x A100 80GB)
# Based on MOVA's fsdp_8gpu.yaml, adapted for DualForce architecture
compute_environment: LOCAL_MACHINE
debug: false
distributed_type: FSDP
downcast_bf16: 'no'
enable_cpu_affinity: false
fsdp_config:
  fsdp_activation_checkpointing: false
  fsdp_auto_wrap_policy: TRANSFORMER_BASED_WRAP
  fsdp_cpu_ram_efficient_loading: false
  fsdp_offload_params: true
  fsdp_reshard_after_forward: true
  fsdp_state_dict_type: SHARDED_STATE_DICT
  # Wrap DiTBlock (shared by video/struct DiT) and bridge cross-attention
  fsdp_transformer_layer_cls_to_wrap: DiTBlock,ConditionalCrossAttentionBlock
  fsdp_version: 2
parallelism_config:
  parallelism_config_cp_size: 2  # Context Parallel (reduced from 4 since model is smaller)
  parallelism_config_dp_replicate_size: 1
  parallelism_config_dp_shard_size: 4
  parallelism_config_tp_size: 1
gpu_ids: all
machine_rank: 0
main_training_function: main
mixed_precision: bf16
num_machines: 1
num_processes: 8
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
